{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT1043 Introduction to Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "\n",
    "### Name:Ng Kai Yi\n",
    "\n",
    "### Student id:32156944\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "In this assignment,I will be reading a csv files which contain the features and labels.I will be analyzing which features I will include to train the model as this will have effect on the performance of the model.Since the analyzing technique is not taught in tutorial,so it is a good chance for me to do the research to improve myself.Then I will seperate the features and label.In this dataset,the label is 'score'.Then I will do the splitting of training and testing dataset.After that, I will normalize the datasets and use the training dataset to train and build my model.Then I will use the testing dataset to do the prediction of score.I will also construct the confusion matrix and analyze it.Then,I will also read a csv file which does not contain the score.I will predict the score for that dataset by using the model.Finally,I will also have a chance to get familiar with kaggle since I have to submit a csv file which contain the essayid and score predicted by using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #import pandas library to do data manipulation and analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essayid</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>apostrophes</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sentences</th>\n",
       "      <th>questions</th>\n",
       "      <th>avg_word_sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS/total_words</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>prompt_words/total_words</th>\n",
       "      <th>synonym_words</th>\n",
       "      <th>synonym_words/total_words</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1457</td>\n",
       "      <td>2153</td>\n",
       "      <td>426</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5.053991</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>26.625000</td>\n",
       "      <td>423.995272</td>\n",
       "      <td>0.995294</td>\n",
       "      <td>207</td>\n",
       "      <td>0.485915</td>\n",
       "      <td>105</td>\n",
       "      <td>0.246479</td>\n",
       "      <td>424</td>\n",
       "      <td>412</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>503</td>\n",
       "      <td>1480</td>\n",
       "      <td>292</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5.068493</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>26.545455</td>\n",
       "      <td>290.993103</td>\n",
       "      <td>0.996552</td>\n",
       "      <td>148</td>\n",
       "      <td>0.506849</td>\n",
       "      <td>77</td>\n",
       "      <td>0.263699</td>\n",
       "      <td>356</td>\n",
       "      <td>345</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253</td>\n",
       "      <td>3964</td>\n",
       "      <td>849</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>4.669022</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>17.326531</td>\n",
       "      <td>843.990544</td>\n",
       "      <td>0.994100</td>\n",
       "      <td>285</td>\n",
       "      <td>0.335689</td>\n",
       "      <td>130</td>\n",
       "      <td>0.153121</td>\n",
       "      <td>750</td>\n",
       "      <td>750</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>988</td>\n",
       "      <td>210</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4.704762</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>207.653784</td>\n",
       "      <td>0.988828</td>\n",
       "      <td>112</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>62</td>\n",
       "      <td>0.295238</td>\n",
       "      <td>217</td>\n",
       "      <td>209</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1450</td>\n",
       "      <td>3139</td>\n",
       "      <td>600</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5.231667</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>594.652150</td>\n",
       "      <td>0.991087</td>\n",
       "      <td>255</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>165</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>702</td>\n",
       "      <td>677</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>1151</td>\n",
       "      <td>2404</td>\n",
       "      <td>467</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5.147752</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>21.227273</td>\n",
       "      <td>462.987069</td>\n",
       "      <td>0.991407</td>\n",
       "      <td>200</td>\n",
       "      <td>0.428266</td>\n",
       "      <td>113</td>\n",
       "      <td>0.241970</td>\n",
       "      <td>529</td>\n",
       "      <td>519</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>1015</td>\n",
       "      <td>1182</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4.904564</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>15.062500</td>\n",
       "      <td>238.655462</td>\n",
       "      <td>0.990272</td>\n",
       "      <td>94</td>\n",
       "      <td>0.390041</td>\n",
       "      <td>67</td>\n",
       "      <td>0.278008</td>\n",
       "      <td>293</td>\n",
       "      <td>283</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>1345</td>\n",
       "      <td>1814</td>\n",
       "      <td>363</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4.997245</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>27.923077</td>\n",
       "      <td>362.329640</td>\n",
       "      <td>0.998153</td>\n",
       "      <td>170</td>\n",
       "      <td>0.468320</td>\n",
       "      <td>107</td>\n",
       "      <td>0.294766</td>\n",
       "      <td>427</td>\n",
       "      <td>415</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>344</td>\n",
       "      <td>1427</td>\n",
       "      <td>287</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4.972125</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>22.076923</td>\n",
       "      <td>284.657277</td>\n",
       "      <td>0.991837</td>\n",
       "      <td>144</td>\n",
       "      <td>0.501742</td>\n",
       "      <td>83</td>\n",
       "      <td>0.289199</td>\n",
       "      <td>323</td>\n",
       "      <td>312</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>1077</td>\n",
       "      <td>2806</td>\n",
       "      <td>542</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5.177122</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>24.636364</td>\n",
       "      <td>538.988889</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>284</td>\n",
       "      <td>0.523985</td>\n",
       "      <td>155</td>\n",
       "      <td>0.285978</td>\n",
       "      <td>596</td>\n",
       "      <td>575</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1332 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essayid  chars  words  commas  apostrophes  punctuations  \\\n",
       "0        1457   2153    426      14            6             0   \n",
       "1         503   1480    292       9            7             0   \n",
       "2         253   3964    849      19           26             1   \n",
       "3         107    988    210       8            7             0   \n",
       "4        1450   3139    600      13            8             0   \n",
       "...       ...    ...    ...     ...          ...           ...   \n",
       "1327     1151   2404    467      16           10             0   \n",
       "1328     1015   1182    241       0           14             0   \n",
       "1329     1345   1814    363       5           11             0   \n",
       "1330      344   1427    287       5            8             0   \n",
       "1331     1077   2806    542      24            6             0   \n",
       "\n",
       "      avg_word_length  sentences  questions  avg_word_sentence         POS  \\\n",
       "0            5.053991         16          0          26.625000  423.995272   \n",
       "1            5.068493         11          0          26.545455  290.993103   \n",
       "2            4.669022         49          2          17.326531  843.990544   \n",
       "3            4.704762         12          0          17.500000  207.653784   \n",
       "4            5.231667         24          1          25.000000  594.652150   \n",
       "...               ...        ...        ...                ...         ...   \n",
       "1327         5.147752         22          0          21.227273  462.987069   \n",
       "1328         4.904564         16          0          15.062500  238.655462   \n",
       "1329         4.997245         13          3          27.923077  362.329640   \n",
       "1330         4.972125         13          1          22.076923  284.657277   \n",
       "1331         5.177122         22          3          24.636364  538.988889   \n",
       "\n",
       "      POS/total_words  prompt_words  prompt_words/total_words  synonym_words  \\\n",
       "0            0.995294           207                  0.485915            105   \n",
       "1            0.996552           148                  0.506849             77   \n",
       "2            0.994100           285                  0.335689            130   \n",
       "3            0.988828           112                  0.533333             62   \n",
       "4            0.991087           255                  0.425000            165   \n",
       "...               ...           ...                       ...            ...   \n",
       "1327         0.991407           200                  0.428266            113   \n",
       "1328         0.990272            94                  0.390041             67   \n",
       "1329         0.998153           170                  0.468320            107   \n",
       "1330         0.991837           144                  0.501742             83   \n",
       "1331         0.994444           284                  0.523985            155   \n",
       "\n",
       "      synonym_words/total_words  unstemmed  stemmed  score  \n",
       "0                      0.246479        424      412      4  \n",
       "1                      0.263699        356      345      4  \n",
       "2                      0.153121        750      750      4  \n",
       "3                      0.295238        217      209      3  \n",
       "4                      0.275000        702      677      4  \n",
       "...                         ...        ...      ...    ...  \n",
       "1327                   0.241970        529      519      4  \n",
       "1328                   0.278008        293      283      3  \n",
       "1329                   0.294766        427      415      3  \n",
       "1330                   0.289199        323      312      3  \n",
       "1331                   0.285978        596      575      4  \n",
       "\n",
       "[1332 rows x 19 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('FIT1043-Essay-Features.csv') \n",
    "#read the 'FIT1043-Essay-Features.csv' file into dataframe and dataset is assigned to it \n",
    "dataset # Display dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essayid</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>apostrophes</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sentences</th>\n",
       "      <th>questions</th>\n",
       "      <th>avg_word_sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS/total_words</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>prompt_words/total_words</th>\n",
       "      <th>synonym_words</th>\n",
       "      <th>synonym_words/total_words</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1332.00000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.00000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.00000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>905.27027</td>\n",
       "      <td>2101.745495</td>\n",
       "      <td>424.485736</td>\n",
       "      <td>14.667417</td>\n",
       "      <td>8.141141</td>\n",
       "      <td>0.47973</td>\n",
       "      <td>4.939762</td>\n",
       "      <td>19.704204</td>\n",
       "      <td>1.222973</td>\n",
       "      <td>23.884687</td>\n",
       "      <td>420.596542</td>\n",
       "      <td>0.989935</td>\n",
       "      <td>198.913664</td>\n",
       "      <td>0.469164</td>\n",
       "      <td>110.16967</td>\n",
       "      <td>0.263846</td>\n",
       "      <td>468.987988</td>\n",
       "      <td>455.507508</td>\n",
       "      <td>3.427177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>526.68760</td>\n",
       "      <td>865.963750</td>\n",
       "      <td>171.873730</td>\n",
       "      <td>10.920781</td>\n",
       "      <td>6.124520</td>\n",
       "      <td>1.27168</td>\n",
       "      <td>0.231071</td>\n",
       "      <td>19.202731</td>\n",
       "      <td>1.847446</td>\n",
       "      <td>11.160020</td>\n",
       "      <td>170.985111</td>\n",
       "      <td>0.007308</td>\n",
       "      <td>82.729266</td>\n",
       "      <td>0.052466</td>\n",
       "      <td>43.96192</td>\n",
       "      <td>0.038870</td>\n",
       "      <td>159.447449</td>\n",
       "      <td>155.751220</td>\n",
       "      <td>0.774275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.231322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.084112</td>\n",
       "      <td>35.647059</td>\n",
       "      <td>0.924771</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>0.027299</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>442.75000</td>\n",
       "      <td>1527.250000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.791679</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.142857</td>\n",
       "      <td>305.406284</td>\n",
       "      <td>0.987758</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>0.435709</td>\n",
       "      <td>81.00000</td>\n",
       "      <td>0.238423</td>\n",
       "      <td>361.000000</td>\n",
       "      <td>350.750000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>914.50000</td>\n",
       "      <td>2029.500000</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.946059</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.030331</td>\n",
       "      <td>406.982869</td>\n",
       "      <td>0.991572</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>0.465852</td>\n",
       "      <td>107.50000</td>\n",
       "      <td>0.262872</td>\n",
       "      <td>463.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1369.75000</td>\n",
       "      <td>2613.500000</td>\n",
       "      <td>525.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.092938</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26.048234</td>\n",
       "      <td>520.739458</td>\n",
       "      <td>0.994425</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>134.00000</td>\n",
       "      <td>0.288277</td>\n",
       "      <td>581.000000</td>\n",
       "      <td>561.250000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1799.00000</td>\n",
       "      <td>6142.000000</td>\n",
       "      <td>1170.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>26.00000</td>\n",
       "      <td>5.681429</td>\n",
       "      <td>642.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>1158.984563</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>669.000000</td>\n",
       "      <td>0.961207</td>\n",
       "      <td>355.00000</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          essayid        chars        words       commas  apostrophes  \\\n",
       "count  1332.00000  1332.000000  1332.000000  1332.000000  1332.000000   \n",
       "mean    905.27027  2101.745495   424.485736    14.667417     8.141141   \n",
       "std     526.68760   865.963750   171.873730    10.920781     6.124520   \n",
       "min       0.00000   169.000000    36.000000     0.000000     2.000000   \n",
       "25%     442.75000  1527.250000   310.000000     7.000000     4.000000   \n",
       "50%     914.50000  2029.500000   411.000000    13.000000     6.000000   \n",
       "75%    1369.75000  2613.500000   525.000000    21.000000    11.000000   \n",
       "max    1799.00000  6142.000000  1170.000000    72.000000    51.000000   \n",
       "\n",
       "       punctuations  avg_word_length    sentences    questions  \\\n",
       "count    1332.00000      1332.000000  1332.000000  1332.000000   \n",
       "mean        0.47973         4.939762    19.704204     1.222973   \n",
       "std         1.27168         0.231071    19.202731     1.847446   \n",
       "min         0.00000         2.231322     0.000000     0.000000   \n",
       "25%         0.00000         4.791679    13.000000     0.000000   \n",
       "50%         0.00000         4.946059    18.000000     1.000000   \n",
       "75%         0.00000         5.092938    24.000000     2.000000   \n",
       "max        26.00000         5.681429   642.000000    17.000000   \n",
       "\n",
       "       avg_word_sentence          POS  POS/total_words  prompt_words  \\\n",
       "count        1332.000000  1332.000000      1332.000000   1332.000000   \n",
       "mean           23.884687   420.596542         0.989935    198.913664   \n",
       "std            11.160020   170.985111         0.007308     82.729266   \n",
       "min             1.084112    35.647059         0.924771     14.000000   \n",
       "25%            19.142857   305.406284         0.987758    144.000000   \n",
       "50%            22.030331   406.982869         0.991572    193.000000   \n",
       "75%            26.048234   520.739458         0.994425    246.000000   \n",
       "max           303.000000  1158.984563         1.000000    669.000000   \n",
       "\n",
       "       prompt_words/total_words  synonym_words  synonym_words/total_words  \\\n",
       "count               1332.000000     1332.00000                1332.000000   \n",
       "mean                   0.469164      110.16967                   0.263846   \n",
       "std                    0.052466       43.96192                   0.038870   \n",
       "min                    0.288889       11.00000                   0.027299   \n",
       "25%                    0.435709       81.00000                   0.238423   \n",
       "50%                    0.465852      107.50000                   0.262872   \n",
       "75%                    0.500000      134.00000                   0.288277   \n",
       "max                    0.961207      355.00000                   0.465517   \n",
       "\n",
       "         unstemmed      stemmed        score  \n",
       "count  1332.000000  1332.000000  1332.000000  \n",
       "mean    468.987988   455.507508     3.427177  \n",
       "std     159.447449   155.751220     0.774275  \n",
       "min      48.000000    50.000000     1.000000  \n",
       "25%     361.000000   350.750000     3.000000  \n",
       "50%     463.000000   448.000000     3.000000  \n",
       "75%     581.000000   561.250000     4.000000  \n",
       "max     750.000000   750.000000     6.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe() #generate descriptive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic descriptive statistics of the values in the file:\n",
    "There are total of 1332 essays with scores.The mean score of the essays is 3.427.The minimum score is 1 and the maximum score is 6.The average of the characters in the essay is 2101.746,and the maximum characters is 6142 while the minimum is 169,hence the range of the characters is great.The average words in the essay is 424.486 and the maximum words is 1170 whereas the minimum words is 36.There is essay which does not include any punctuations,questions,and commas,since the minimum in punctuations,questions and commas are 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>POS</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>synonym_words</th>\n",
       "      <th>synonym_words/total_words</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2153</td>\n",
       "      <td>426</td>\n",
       "      <td>14</td>\n",
       "      <td>5.053991</td>\n",
       "      <td>423.995272</td>\n",
       "      <td>207</td>\n",
       "      <td>105</td>\n",
       "      <td>0.246479</td>\n",
       "      <td>424</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1480</td>\n",
       "      <td>292</td>\n",
       "      <td>9</td>\n",
       "      <td>5.068493</td>\n",
       "      <td>290.993103</td>\n",
       "      <td>148</td>\n",
       "      <td>77</td>\n",
       "      <td>0.263699</td>\n",
       "      <td>356</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3964</td>\n",
       "      <td>849</td>\n",
       "      <td>19</td>\n",
       "      <td>4.669022</td>\n",
       "      <td>843.990544</td>\n",
       "      <td>285</td>\n",
       "      <td>130</td>\n",
       "      <td>0.153121</td>\n",
       "      <td>750</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>988</td>\n",
       "      <td>210</td>\n",
       "      <td>8</td>\n",
       "      <td>4.704762</td>\n",
       "      <td>207.653784</td>\n",
       "      <td>112</td>\n",
       "      <td>62</td>\n",
       "      <td>0.295238</td>\n",
       "      <td>217</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3139</td>\n",
       "      <td>600</td>\n",
       "      <td>13</td>\n",
       "      <td>5.231667</td>\n",
       "      <td>594.652150</td>\n",
       "      <td>255</td>\n",
       "      <td>165</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>702</td>\n",
       "      <td>677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>2404</td>\n",
       "      <td>467</td>\n",
       "      <td>16</td>\n",
       "      <td>5.147752</td>\n",
       "      <td>462.987069</td>\n",
       "      <td>200</td>\n",
       "      <td>113</td>\n",
       "      <td>0.241970</td>\n",
       "      <td>529</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>1182</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>4.904564</td>\n",
       "      <td>238.655462</td>\n",
       "      <td>94</td>\n",
       "      <td>67</td>\n",
       "      <td>0.278008</td>\n",
       "      <td>293</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>1814</td>\n",
       "      <td>363</td>\n",
       "      <td>5</td>\n",
       "      <td>4.997245</td>\n",
       "      <td>362.329640</td>\n",
       "      <td>170</td>\n",
       "      <td>107</td>\n",
       "      <td>0.294766</td>\n",
       "      <td>427</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>1427</td>\n",
       "      <td>287</td>\n",
       "      <td>5</td>\n",
       "      <td>4.972125</td>\n",
       "      <td>284.657277</td>\n",
       "      <td>144</td>\n",
       "      <td>83</td>\n",
       "      <td>0.289199</td>\n",
       "      <td>323</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>2806</td>\n",
       "      <td>542</td>\n",
       "      <td>24</td>\n",
       "      <td>5.177122</td>\n",
       "      <td>538.988889</td>\n",
       "      <td>284</td>\n",
       "      <td>155</td>\n",
       "      <td>0.285978</td>\n",
       "      <td>596</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1332 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      chars  words  commas  avg_word_length         POS  prompt_words  \\\n",
       "0      2153    426      14         5.053991  423.995272           207   \n",
       "1      1480    292       9         5.068493  290.993103           148   \n",
       "2      3964    849      19         4.669022  843.990544           285   \n",
       "3       988    210       8         4.704762  207.653784           112   \n",
       "4      3139    600      13         5.231667  594.652150           255   \n",
       "...     ...    ...     ...              ...         ...           ...   \n",
       "1327   2404    467      16         5.147752  462.987069           200   \n",
       "1328   1182    241       0         4.904564  238.655462            94   \n",
       "1329   1814    363       5         4.997245  362.329640           170   \n",
       "1330   1427    287       5         4.972125  284.657277           144   \n",
       "1331   2806    542      24         5.177122  538.988889           284   \n",
       "\n",
       "      synonym_words  synonym_words/total_words  unstemmed  stemmed  \n",
       "0               105                   0.246479        424      412  \n",
       "1                77                   0.263699        356      345  \n",
       "2               130                   0.153121        750      750  \n",
       "3                62                   0.295238        217      209  \n",
       "4               165                   0.275000        702      677  \n",
       "...             ...                        ...        ...      ...  \n",
       "1327            113                   0.241970        529      519  \n",
       "1328             67                   0.278008        293      283  \n",
       "1329            107                   0.294766        427      415  \n",
       "1330             83                   0.289199        323      312  \n",
       "1331            155                   0.285978        596      575  \n",
       "\n",
       "[1332 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.iloc[:,[1,2,3,6,10,12,14,15,16,17]]\n",
    "# X is assigned to the features that I wanted which include chars,words,commas,avg_word_length,POS,prompt_words,synonym_words,\n",
    "# synonym_words / total_words, unstemmed and stemmed\n",
    "X #Display X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation on supervised machine learning and the notion of labelled data:\n",
    "In supervised machine learning,we train the machine by using the labeled data and the supervised machine learning algorithm learn from the labelled input data and predict the output for unforeseen data.Labeled data means that the data is marked up and tagged with the correct answer we want the machine to predict and the data is attached with meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation on training and test datasets:\n",
    "Training dataset is a sample set of data used to train the model in order to predict the output for unforeseen data.Training dataset is also used to fit the parameters of classifier.\n",
    "\n",
    "Test dataset is a sample set of data used to test the trained model,to evaluate the performance of the trained model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, ..., 3, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset.iloc[:,-1].values\n",
    "# y is assigned to the label,which is 'score'\n",
    "y #Display y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# import train_test_split from sklearn.model_selection to split the data.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    " X, y, test_size = 0.25, random_state = 42\n",
    ")\n",
    "#Splitting features and label into training and testing datasets.X_train is assigned to features' training dataset and \n",
    "#X_test is assigned to features' testing dataset whereas y_train is assigned to the label's training dataset and \n",
    "#y_test is assigned to the label's testing dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.09900000e+03, 4.20000000e+02, 1.10000000e+01, ...,\n",
       "        2.97619048e-01, 4.47000000e+02, 4.42000000e+02],\n",
       "       [1.18100000e+03, 2.43000000e+02, 0.00000000e+00, ...,\n",
       "        3.00411523e-01, 2.80000000e+02, 2.66000000e+02],\n",
       "       [1.10900000e+03, 2.31000000e+02, 1.30000000e+01, ...,\n",
       "        2.07792208e-01, 2.89000000e+02, 2.84000000e+02],\n",
       "       ...,\n",
       "       [1.56300000e+03, 3.27000000e+02, 2.00000000e+00, ...,\n",
       "        3.45565749e-01, 3.36000000e+02, 3.19000000e+02],\n",
       "       [1.81700000e+03, 4.10000000e+02, 1.00000000e+01, ...,\n",
       "        2.51219512e-01, 3.97000000e+02, 3.87000000e+02],\n",
       "       [6.05000000e+02, 1.33000000e+02, 7.00000000e+00, ...,\n",
       "        2.63157895e-01, 1.64000000e+02, 1.62000000e+02]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train #Display X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.36900000e+03, 4.87000000e+02, 7.00000000e+00, ...,\n",
       "        2.62833676e-01, 4.68000000e+02, 4.56000000e+02],\n",
       "       [2.61900000e+03, 5.12000000e+02, 8.00000000e+00, ...,\n",
       "        2.34375000e-01, 6.49000000e+02, 6.27000000e+02],\n",
       "       [1.45900000e+03, 3.13000000e+02, 1.90000000e+01, ...,\n",
       "        2.93929712e-01, 3.80000000e+02, 3.66000000e+02],\n",
       "       ...,\n",
       "       [1.97000000e+03, 3.87000000e+02, 1.10000000e+01, ...,\n",
       "        2.53229974e-01, 4.38000000e+02, 4.16000000e+02],\n",
       "       [1.15600000e+03, 2.19000000e+02, 1.00000000e+01, ...,\n",
       "        2.37442922e-01, 2.97000000e+02, 2.95000000e+02],\n",
       "       [2.30100000e+03, 4.98000000e+02, 1.70000000e+01, ...,\n",
       "        2.57028112e-01, 5.49000000e+02, 5.34000000e+02]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test #Display X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3, 4, 4, 3, 6, 2, 3, 2, 4, 4, 3, 4, 4, 4, 5, 3, 2, 3,\n",
       "       4, 4, 4, 2, 4, 4, 4, 1, 3, 5, 2, 3, 4, 1, 4, 4, 3, 4, 3, 3, 4, 4,\n",
       "       3, 3, 3, 5, 2, 3, 3, 4, 3, 3, 3, 4, 2, 2, 3, 3, 3, 4, 2, 3, 3, 4,\n",
       "       4, 3, 4, 4, 3, 3, 2, 4, 3, 4, 3, 4, 3, 4, 3, 4, 4, 2, 4, 4, 4, 2,\n",
       "       5, 3, 4, 3, 4, 5, 4, 4, 3, 3, 4, 4, 2, 3, 4, 2, 3, 4, 4, 4, 3, 3,\n",
       "       3, 4, 4, 4, 3, 4, 4, 3, 5, 4, 4, 4, 3, 3, 3, 4, 4, 3, 3, 4, 3, 3,\n",
       "       4, 1, 3, 3, 3, 3, 3, 4, 3, 4, 4, 2, 4, 3, 3, 3, 4, 4, 2, 4, 4, 4,\n",
       "       5, 3, 4, 3, 2, 4, 3, 4, 4, 3, 4, 3, 4, 2, 3, 3, 5, 3, 3, 3, 4, 4,\n",
       "       3, 3, 4, 3, 2, 5, 3, 4, 3, 3, 4, 3, 3, 3, 4, 3, 4, 1, 2, 4, 4, 4,\n",
       "       4, 2, 5, 3, 4, 2, 4, 3, 4, 3, 4, 4, 3, 4, 3, 4, 3, 4, 3, 3, 3, 3,\n",
       "       3, 4, 3, 4, 4, 4, 4, 3, 3, 3, 4, 3, 3, 2, 3, 3, 4, 3, 4, 3, 4, 3,\n",
       "       4, 3, 3, 4, 4, 4, 5, 3, 4, 3, 4, 3, 4, 2, 4, 4, 4, 3, 3, 4, 3, 3,\n",
       "       3, 2, 3, 3, 3, 3, 4, 3, 4, 4, 2, 3, 3, 4, 3, 4, 2, 5, 4, 4, 4, 3,\n",
       "       3, 4, 3, 4, 3, 3, 2, 5, 2, 5, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3,\n",
       "       4, 3, 3, 4, 3, 4, 4, 3, 4, 5, 4, 3, 3, 4, 3, 3, 3, 2, 4, 3, 4, 3,\n",
       "       3, 3, 4, 2, 4, 2, 5, 4, 5, 3, 4, 4, 3, 3, 3, 2, 3, 3, 3, 3, 4, 3,\n",
       "       2, 4, 4, 3, 3, 3, 3, 3, 5, 4, 3, 4, 3, 4, 4, 4, 4, 4, 3, 2, 3, 3,\n",
       "       3, 3, 2, 2, 3, 1, 3, 3, 3, 4, 2, 3, 4, 2, 4, 4, 4, 4, 4, 2, 3, 3,\n",
       "       3, 4, 4, 4, 3, 2, 4, 4, 3, 5, 3, 3, 2, 4, 4, 2, 3, 3, 3, 4, 3, 4,\n",
       "       3, 3, 3, 3, 4, 3, 3, 3, 3, 4, 3, 4, 3, 3, 4, 4, 4, 5, 3, 4, 4, 3,\n",
       "       4, 3, 5, 2, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 3, 5, 3, 3, 4, 4, 4,\n",
       "       3, 3, 3, 3, 3, 4, 4, 3, 5, 3, 3, 3, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3,\n",
       "       3, 4, 2, 3, 4, 3, 3, 3, 4, 4, 3, 2, 3, 4, 4, 4, 4, 4, 5, 3, 4, 4,\n",
       "       2, 4, 4, 4, 3, 4, 4, 3, 2, 4, 3, 3, 4, 3, 4, 4, 4, 2, 4, 4, 3, 2,\n",
       "       3, 4, 3, 5, 4, 4, 4, 4, 4, 4, 4, 3, 5, 4, 4, 5, 2, 4, 5, 4, 4, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 1, 3, 4, 3, 4, 4, 4, 3, 3, 5, 1, 3, 3, 3, 4,\n",
       "       4, 4, 3, 3, 4, 4, 3, 3, 4, 4, 2, 4, 3, 2, 3, 3, 4, 4, 4, 3, 3, 4,\n",
       "       4, 3, 3, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 3, 4, 3, 3, 4, 4, 3, 3, 3,\n",
       "       3, 5, 3, 3, 4, 3, 4, 3, 4, 4, 4, 3, 4, 4, 3, 3, 2, 4, 3, 3, 4, 4,\n",
       "       3, 4, 3, 3, 4, 4, 3, 3, 3, 3, 4, 3, 5, 3, 3, 4, 3, 4, 4, 5, 3, 4,\n",
       "       4, 4, 3, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 3, 2, 4, 3, 4, 1, 4, 3,\n",
       "       3, 4, 2, 4, 4, 4, 4, 3, 3, 4, 3, 4, 2, 4, 4, 3, 3, 3, 2, 3, 3, 3,\n",
       "       4, 3, 4, 2, 6, 4, 2, 3, 1, 4, 4, 3, 5, 4, 2, 3, 3, 4, 3, 2, 4, 3,\n",
       "       3, 3, 3, 3, 4, 5, 4, 3, 4, 4, 5, 4, 3, 4, 4, 3, 6, 4, 4, 4, 4, 4,\n",
       "       4, 1, 3, 5, 3, 3, 3, 4, 3, 4, 4, 3, 4, 3, 4, 4, 2, 3, 3, 4, 4, 3,\n",
       "       4, 4, 2, 3, 3, 3, 3, 1, 3, 4, 2, 3, 3, 3, 2, 3, 4, 4, 4, 4, 3, 4,\n",
       "       2, 3, 3, 4, 4, 4, 3, 4, 3, 3, 2, 3, 4, 4, 3, 4, 4, 4, 3, 2, 3, 3,\n",
       "       2, 4, 3, 2, 3, 5, 2, 3, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 2, 4, 4, 4,\n",
       "       5, 4, 4, 3, 4, 3, 4, 5, 5, 3, 3, 3, 2, 4, 4, 3, 3, 4, 4, 5, 3, 3,\n",
       "       5, 4, 4, 3, 4, 2, 4, 3, 4, 2, 3, 4, 3, 4, 3, 4, 3, 4, 4, 4, 4, 3,\n",
       "       4, 4, 4, 4, 3, 3, 3, 3, 4, 3, 2, 4, 4, 3, 3, 3, 5, 4, 3, 4, 3, 4,\n",
       "       4, 3, 4, 2, 4, 3, 4, 4, 2, 3, 3, 4, 4, 3, 3, 4, 3, 4, 4, 4, 3, 1,\n",
       "       4, 3, 3, 4, 3, 3, 4, 4, 3, 4, 2, 4, 3, 3, 4, 3, 3, 3, 4, 2, 2, 4,\n",
       "       3, 4, 3, 4, 2, 4, 3, 4, 3, 3, 3, 3, 4, 4, 3, 3, 4, 3, 4, 3, 3, 3,\n",
       "       2, 1, 3, 3, 4, 4, 4, 3, 5, 5, 3, 3, 3, 4, 3, 5, 4, 4, 3, 2, 4, 3,\n",
       "       4, 3, 3, 4, 3, 3, 3, 4, 2], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train #Display y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 3, 2, 3, 4, 4, 4, 2, 4, 4, 4, 3, 4, 4, 4, 4, 3, 3, 3, 4, 4,\n",
       "       2, 4, 2, 3, 4, 3, 3, 3, 3, 5, 3, 5, 3, 3, 3, 3, 4, 3, 2, 4, 4, 4,\n",
       "       4, 3, 4, 1, 4, 3, 4, 3, 4, 4, 4, 2, 4, 3, 4, 4, 4, 3, 6, 4, 4, 5,\n",
       "       3, 4, 3, 3, 3, 4, 3, 2, 4, 2, 4, 4, 3, 5, 3, 2, 5, 4, 4, 4, 4, 4,\n",
       "       1, 3, 3, 3, 4, 4, 3, 4, 4, 4, 3, 4, 3, 3, 4, 4, 4, 5, 3, 4, 4, 3,\n",
       "       4, 3, 3, 3, 4, 5, 3, 3, 4, 3, 3, 2, 4, 4, 3, 4, 4, 2, 3, 4, 4, 3,\n",
       "       4, 3, 3, 3, 2, 3, 3, 4, 3, 4, 4, 3, 3, 4, 4, 3, 4, 3, 3, 4, 4, 5,\n",
       "       3, 1, 3, 4, 1, 3, 4, 3, 3, 2, 3, 4, 4, 3, 4, 3, 3, 3, 5, 3, 4, 3,\n",
       "       3, 4, 3, 3, 3, 3, 2, 4, 3, 4, 3, 3, 3, 2, 3, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 5, 4, 3, 4, 3, 4, 4, 4, 4, 4, 3, 3, 3, 4, 3, 3, 3, 2, 4,\n",
       "       2, 3, 3, 3, 5, 3, 3, 3, 4, 2, 3, 4, 3, 4, 4, 3, 4, 4, 4, 3, 4, 4,\n",
       "       2, 4, 3, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 1, 3, 3, 4, 4, 3, 4,\n",
       "       4, 4, 4, 3, 4, 4, 4, 4, 5, 4, 2, 4, 4, 4, 5, 5, 4, 4, 4, 4, 4, 3,\n",
       "       4, 4, 2, 3, 3, 3, 4, 2, 3, 4, 3, 3, 4, 4, 3, 3, 4, 3, 4, 2, 4, 3,\n",
       "       4, 4, 4, 3, 2, 3, 4, 4, 4, 3, 3, 3, 4, 3, 4, 4, 3, 3, 3, 4, 3, 3,\n",
       "       4, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test #Display y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between binary and multi-class classification:\n",
    "Binary classification is a type of supervised learning because the training dataset is labelled.Moreover,Binary classification is the classification that involve only two class labels.\n",
    "\n",
    "Binary classification is the task of classifying given dataset into one of two classes based on the features,one will be the normal state and the other one will be abnormal state.For example,medical testing on whether the patient has breast cancer,'the patient has breast cancer'class will be the abnormal state whereas 'the patient does not have breast cancer'is the normal state.\n",
    "\n",
    "The algorithm commonly used for the binary classification is logistic regression,decision trees,random forests,support vector machine and neural networks.The results of the binary classification can be represented by the (2x2) matrix.\n",
    "\n",
    "### --------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Multi-class classification is also a type of supervised learning as the training dataset is labelled.Multi-class classification \n",
    "is the classification that involve more than two class labels.\n",
    "\n",
    "Multi-class classification is the task of classifying the samples into one of three or more classes based on the features.Each sample can only be assigned to one label out of many.For instance,classification of the species of dog based on the features on a given image,the dog can only be labelled as 'poodle' but not 'poodle' and 'bulldog'.\n",
    "\n",
    "The algorithm commonly used for the multi-class classification is the k-Nearest Neighbors,decision trees,random forests and naive bayes.There are ways to reduce the problem of multi-class classification to multiple binary classification like one vs rest and one vs one.The results of the binary classification can be represented by the (3x3) or larger dimension matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation on the purpose of normalised /scaling of data:\n",
    "Most of the machine learning algorithms calculate the distance between two data points by Eucledian distance to determine their similarities.Hence if one the features has a great range of values then the distance calculated will be greatly affected by this feature.Moreover,if the features have different scale,the feature with greater magnitude will tend to be given greater weightage.Therefore,we normalise/scale the data before we apply the distance based algorithm so that all the features contribute proportionally to the final distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#importing StandardScaler from sklearn.preprocessing\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train) # Scale training dataset so that it has the mean of 0 and certain standard deviation\n",
    "X_test = sc.transform(X_test) \n",
    "# normalize the testing dataset by using the mean of 0 and certain standard deviation stored in the StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.94014264e-04, -2.35692855e-02, -3.35382185e-01, ...,\n",
       "         8.59185435e-01, -1.40768375e-01, -8.90135489e-02],\n",
       "       [-1.07399585e+00, -1.06520682e+00, -1.32160505e+00, ...,\n",
       "         9.31528414e-01, -1.19262533e+00, -1.22246649e+00],\n",
       "       [-1.15817639e+00, -1.13582631e+00, -1.56068938e-01, ...,\n",
       "        -1.46790475e+00, -1.13593843e+00, -1.10654517e+00],\n",
       "       ...,\n",
       "       [-6.27371340e-01, -5.70870363e-01, -1.14229180e+00, ...,\n",
       "         2.10131193e+00, -8.39906830e-01, -8.81142594e-01],\n",
       "       [-3.30401115e-01, -8.24188638e-02, -4.25038809e-01, ...,\n",
       "        -3.42859577e-01, -4.55695607e-01, -4.43217593e-01],\n",
       "       [-1.74744014e+00, -1.71255218e+00, -6.94008681e-01, ...,\n",
       "        -3.35790329e-02, -1.92325651e+00, -1.89223414e+00]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train # Display features' training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.14982997e-01,  3.70722889e-01, -6.94008681e-01, ...,\n",
       "        -4.19783805e-02, -8.49893712e-03,  1.14748057e-03],\n",
       "       [ 6.07276525e-01,  5.17846834e-01, -6.04352057e-01, ...,\n",
       "        -7.79240269e-01,  1.13153764e+00,  1.10240006e+00],\n",
       "       [-7.48965448e-01, -6.53259773e-01,  3.81870805e-01, ...,\n",
       "         7.63608015e-01, -5.62770866e-01, -5.78459138e-01],\n",
       "       ...,\n",
       "       [-1.51517475e-01, -2.17772894e-01, -3.35382185e-01, ...,\n",
       "        -2.90775741e-01, -1.97455276e-01, -2.56455461e-01],\n",
       "       [-1.10322520e+00, -1.20644581e+00, -4.25038809e-01, ...,\n",
       "        -6.99761450e-01, -1.08555007e+00, -1.03570436e+00],\n",
       "       [ 2.35479157e-01,  4.35457425e-01,  2.02557558e-01, ...,\n",
       "        -1.92379653e-01,  5.01683179e-01,  5.03473216e-01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test #Display features' testing dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation on SVM:\n",
    "Support vector machine find the best hyperplane which seperate the classes by finding the greatest margin,which is the distance between the line and the support vector while linear regression find the best line by using the equation Y = a + bX, X is the explanatory variable,Y is the dependent variable and a is the intercept and b is the slope.Support vector machine is based on the geometrical properties of the data whereas linear regression is based on the statistical way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation on kernel in SVM:\n",
    "Kernel in Support Vector Machine is used to refer the kernel trick,which is a set of mathematical functions used by the Support Vector Machine.It transform the data which cannot be seperated linearly to the data which can be seperated linearly.Kernel function take the data as input and transform it to a high-dimensional feature space so that it can be seperated linearly.There are different types of kernel functions which are 'linear','non-linear','polynomial','radial basis function' and 'sigmoid'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, gamma=0.001)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm # importing svm from sklearn \n",
    "model = svm.SVC(C = 1000, gamma = 0.001, kernel = 'rbf') \n",
    "# Use Support Vector Classifier as classifer and C is set to 1000, gamma is set to 0.001 and kernel is radial basis function\n",
    "# and model is assigned to it.\n",
    "model.fit(X_train, y_train)\n",
    "# Fit the features' training data and label's training data to the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 3, 1, 3, 4, 3, 4, 2, 4, 4, 4, 3, 3, 4, 3, 3, 3, 3, 3, 4, 3,\n",
       "       2, 4, 3, 4, 4, 3, 3, 4, 4, 4, 3, 4, 3, 3, 4, 3, 4, 3, 2, 4, 4, 4,\n",
       "       4, 3, 3, 2, 4, 2, 4, 3, 4, 4, 4, 2, 4, 3, 4, 4, 4, 3, 5, 4, 4, 4,\n",
       "       3, 4, 4, 3, 3, 4, 3, 2, 4, 3, 4, 4, 3, 4, 3, 3, 4, 4, 3, 3, 4, 4,\n",
       "       2, 3, 4, 3, 4, 4, 3, 4, 4, 4, 3, 3, 4, 3, 3, 4, 4, 4, 4, 4, 4, 3,\n",
       "       4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 3, 2, 4, 3, 3, 4, 4, 3, 4, 3, 3, 4,\n",
       "       4, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3, 3, 4, 3,\n",
       "       3, 2, 4, 4, 2, 3, 4, 3, 4, 2, 3, 4, 4, 3, 4, 3, 4, 3, 4, 3, 4, 4,\n",
       "       3, 4, 3, 3, 3, 3, 2, 4, 3, 4, 3, 3, 3, 2, 3, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 4, 3, 4, 4, 2, 3,\n",
       "       3, 3, 4, 3, 4, 3, 3, 3, 5, 2, 3, 4, 4, 4, 4, 3, 4, 4, 3, 3, 4, 4,\n",
       "       2, 4, 3, 4, 4, 3, 2, 3, 3, 3, 4, 3, 4, 4, 3, 2, 3, 3, 4, 3, 3, 4,\n",
       "       3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 4,\n",
       "       3, 4, 2, 3, 3, 3, 3, 2, 3, 4, 3, 4, 4, 4, 3, 4, 4, 2, 4, 3, 4, 3,\n",
       "       4, 4, 4, 4, 2, 3, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 3, 3, 4, 3, 2,\n",
       "       3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test) \n",
    "# Predict the score by fitting features' testing dataset y_pred is assigned to it\n",
    "y_pred\n",
    "# Display the predicted score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   5,   0,   0,   0,   0],\n",
       "       [  1,  15,   8,   0,   0,   0],\n",
       "       [  0,   4,  94,  35,   0,   0],\n",
       "       [  0,   0,  30, 125,   1,   0],\n",
       "       [  0,   0,   1,  13,   0,   0],\n",
       "       [  0,   0,   0,   0,   1,   0]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "#Importing confusion_matrix from sklearn.metrics\n",
    "cm = confusion_matrix(y_test, y_pred) \n",
    "#Construct confusion matrix by using label's testing dataset and predicted score.\n",
    "cm\n",
    "#Display confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation on confusion matrix:\n",
    "Confusion matrix is a N x N matrix which is used to assess the performance of the classification model,N is the number of target classes.Confusion matrix will compare the predicted value with the actual values,hence we can see what errors our model has made and how well it perform.\n",
    "\n",
    "The confusion matrix I constructed based on y_test and y_pred showed that for score 1, 5 and 6,the model failed to classify any of the samples to their actual score,which means there is no True Positive for score 1, 5 and 6.Therefore,the precision for score 1, 5 and 6 is 0.For score 2, 15 out of 24 samples correctly classified to their actual score,the precision is 0.62.For score 3,94 out of 133 samples correctly classified to their actual score,the precision is 0.71,for score 4, 124 out of 156 correctly classified to their actual score,the precision is 0.72.The accuracy is calculated as the ratio of the total number of samples correctly classified to the total number of samples.The accuracy is 0.703."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.62      0.62      0.62        24\n",
      "           3       0.71      0.71      0.71       133\n",
      "           4       0.72      0.80      0.76       156\n",
      "           5       0.00      0.00      0.00        14\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.70       333\n",
      "   macro avg       0.34      0.36      0.35       333\n",
      "weighted avg       0.67      0.70      0.68       333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#Importing classification_report from sklearn.metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "#Printing the classification_report based on the label's testing dataset and predicted score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7027027027027027"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics #importing metrics from sklearn\n",
    "metrics.accuracy_score(y_test, y_pred) \n",
    "#Get the accuracy of the confusion matrix constructed based on label's testing dataset and predicted score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation on QWK:\n",
    "QWK stands for quadratic weighted kappa.Quadratic weighted kappa is the measure of agreement between the predicted data by the model and the labelled data of the same object.Firstly,it will start with the accuracy by finding the proportion of all the objects which is classfied into the actual class(label).Then the value will be adjusted based on the probability of the model's predictions are same as the label(actual class) by chance.QWK can range from -1 to 1, 0 means random agreement between a model's prediction and the label(actual class), 1 means perfect agreement, and if Quadratic weighted kappa falls below 0,it indicates less than chance agreement.If it is between 0.01 to 0.20,it means poor agreement,if it is between 0.21 to 0.40,it means fair agreement,if it is between 0.41 to 0.60,it means moderate agreement,if it is between 0.61 to 0.80,it means substantial agreement,if it is between 0.81 to 1.00,it means almost perfect agreement\n",
    "\n",
    "### --------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "This explanation is based on this assignment,which the label is score,which has 6 possible score,range from 1-6.\n",
    "To calculate Quadratic Weighted Kappa,\n",
    "\n",
    "1)Firstly,we have to construct a 6 x 6 confusion matrix,(O) based on the predicted score and the actual score.\n",
    "\n",
    "2)Then we construct a 6 x 6 matrix of weights,(w) based on the difference between the actual and the predicted score.\n",
    "\n",
    "3)Construct the actual score's histogram vector and the predicted score's histogram vector.\n",
    "\n",
    "4)Then construct a 6 x 6 matrix of expected score,(E),which is calculated by the outer product of actual score's histogram vector and the predicted score's histogram vectoconfusion matrixr.\n",
    "\n",
    "5)Then normalize matrix of expected score and confusion matrix so that they have the same sum.\n",
    "\n",
    "6)Then the quadratic weighted kappa can be calculated by using 3 matrices constructed.\n",
    "  Quadratic weighted kappa = 1 -  [(∑i,j wi,j Oij) / (∑i,j wi,j Ei,j.)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6957433086101257"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "#importing cohen_kappa_score from sklearn.metrics\n",
    "cohen_kappa_score(y_test,y_pred, labels=None, weights='quadratic', sample_weight=None) \n",
    "#calculate the Quadratic weighted kappa score by using the function cohen_kappa_score and fitting in y_test and y_pred.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation on QWK score:\n",
    "The QWK score I got is 0.6957. 0.6957 is between 0.61 and 0.80 which indicates that the agreement between the score predicted by the model and the actual score is substantial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essayid</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>apostrophes</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sentences</th>\n",
       "      <th>questions</th>\n",
       "      <th>avg_word_sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS/total_words</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>prompt_words/total_words</th>\n",
       "      <th>synonym_words</th>\n",
       "      <th>synonym_words/total_words</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1623</td>\n",
       "      <td>4332</td>\n",
       "      <td>900</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4.813333</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>23.076923</td>\n",
       "      <td>893.988852</td>\n",
       "      <td>0.993321</td>\n",
       "      <td>392</td>\n",
       "      <td>0.435556</td>\n",
       "      <td>196</td>\n",
       "      <td>0.217778</td>\n",
       "      <td>750</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1143</td>\n",
       "      <td>1465</td>\n",
       "      <td>280</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5.232143</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>278.321343</td>\n",
       "      <td>0.994005</td>\n",
       "      <td>131</td>\n",
       "      <td>0.467857</td>\n",
       "      <td>51</td>\n",
       "      <td>0.182143</td>\n",
       "      <td>339</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>660</td>\n",
       "      <td>1696</td>\n",
       "      <td>325</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.218462</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>17.105263</td>\n",
       "      <td>321.316770</td>\n",
       "      <td>0.988667</td>\n",
       "      <td>178</td>\n",
       "      <td>0.547692</td>\n",
       "      <td>92</td>\n",
       "      <td>0.283077</td>\n",
       "      <td>352</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1596</td>\n",
       "      <td>2640</td>\n",
       "      <td>555</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>4.756757</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>19.821429</td>\n",
       "      <td>551.989150</td>\n",
       "      <td>0.994575</td>\n",
       "      <td>228</td>\n",
       "      <td>0.410811</td>\n",
       "      <td>107</td>\n",
       "      <td>0.192793</td>\n",
       "      <td>632</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>846</td>\n",
       "      <td>2844</td>\n",
       "      <td>596</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4.771812</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>24.833333</td>\n",
       "      <td>593.658810</td>\n",
       "      <td>0.996072</td>\n",
       "      <td>279</td>\n",
       "      <td>0.468121</td>\n",
       "      <td>138</td>\n",
       "      <td>0.231544</td>\n",
       "      <td>626</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1226</td>\n",
       "      <td>1208</td>\n",
       "      <td>242</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4.991736</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>18.615385</td>\n",
       "      <td>237.327684</td>\n",
       "      <td>0.980693</td>\n",
       "      <td>135</td>\n",
       "      <td>0.557851</td>\n",
       "      <td>58</td>\n",
       "      <td>0.239669</td>\n",
       "      <td>244</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>862</td>\n",
       "      <td>4039</td>\n",
       "      <td>817</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>4.943696</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>17.382979</td>\n",
       "      <td>812.656033</td>\n",
       "      <td>0.994683</td>\n",
       "      <td>386</td>\n",
       "      <td>0.472460</td>\n",
       "      <td>210</td>\n",
       "      <td>0.257038</td>\n",
       "      <td>750</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1562</td>\n",
       "      <td>2448</td>\n",
       "      <td>468</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5.230769</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>21.272727</td>\n",
       "      <td>465.656652</td>\n",
       "      <td>0.994993</td>\n",
       "      <td>224</td>\n",
       "      <td>0.478632</td>\n",
       "      <td>101</td>\n",
       "      <td>0.215812</td>\n",
       "      <td>540</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1336</td>\n",
       "      <td>1081</td>\n",
       "      <td>214</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5.051402</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>19.454545</td>\n",
       "      <td>212.990566</td>\n",
       "      <td>0.995283</td>\n",
       "      <td>114</td>\n",
       "      <td>0.532710</td>\n",
       "      <td>63</td>\n",
       "      <td>0.294393</td>\n",
       "      <td>259</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1171</td>\n",
       "      <td>2094</td>\n",
       "      <td>433</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4.836028</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>22.789474</td>\n",
       "      <td>426.651090</td>\n",
       "      <td>0.985337</td>\n",
       "      <td>221</td>\n",
       "      <td>0.510393</td>\n",
       "      <td>121</td>\n",
       "      <td>0.279446</td>\n",
       "      <td>501</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     essayid  chars  words  commas  apostrophes  punctuations  \\\n",
       "0       1623   4332    900      28           13             0   \n",
       "1       1143   1465    280      11            3             1   \n",
       "2        660   1696    325      17            2             0   \n",
       "3       1596   2640    555      20           17             0   \n",
       "4        846   2844    596      33            4             1   \n",
       "..       ...    ...    ...     ...          ...           ...   \n",
       "194     1226   1208    242       8            8             0   \n",
       "195      862   4039    817      24           11             1   \n",
       "196     1562   2448    468      22            7             0   \n",
       "197     1336   1081    214      14            5             0   \n",
       "198     1171   2094    433      11           12             0   \n",
       "\n",
       "     avg_word_length  sentences  questions  avg_word_sentence         POS  \\\n",
       "0           4.813333         39          1          23.076923  893.988852   \n",
       "1           5.232143         14          3          20.000000  278.321343   \n",
       "2           5.218462         19          1          17.105263  321.316770   \n",
       "3           4.756757         28          0          19.821429  551.989150   \n",
       "4           4.771812         24          9          24.833333  593.658810   \n",
       "..               ...        ...        ...                ...         ...   \n",
       "194         4.991736         13          0          18.615385  237.327684   \n",
       "195         4.943696         47          2          17.382979  812.656033   \n",
       "196         5.230769         22          0          21.272727  465.656652   \n",
       "197         5.051402         11          0          19.454545  212.990566   \n",
       "198         4.836028         19          0          22.789474  426.651090   \n",
       "\n",
       "     POS/total_words  prompt_words  prompt_words/total_words  synonym_words  \\\n",
       "0           0.993321           392                  0.435556            196   \n",
       "1           0.994005           131                  0.467857             51   \n",
       "2           0.988667           178                  0.547692             92   \n",
       "3           0.994575           228                  0.410811            107   \n",
       "4           0.996072           279                  0.468121            138   \n",
       "..               ...           ...                       ...            ...   \n",
       "194         0.980693           135                  0.557851             58   \n",
       "195         0.994683           386                  0.472460            210   \n",
       "196         0.994993           224                  0.478632            101   \n",
       "197         0.995283           114                  0.532710             63   \n",
       "198         0.985337           221                  0.510393            121   \n",
       "\n",
       "     synonym_words/total_words  unstemmed  stemmed  \n",
       "0                     0.217778        750      750  \n",
       "1                     0.182143        339      316  \n",
       "2                     0.283077        352      337  \n",
       "3                     0.192793        632      605  \n",
       "4                     0.231544        626      607  \n",
       "..                         ...        ...      ...  \n",
       "194                   0.239669        244      242  \n",
       "195                   0.257038        750      750  \n",
       "196                   0.215812        540      526  \n",
       "197                   0.294393        259      256  \n",
       "198                   0.279446        501      478  \n",
       "\n",
       "[199 rows x 18 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('FIT1043-Essay-Features-Submission.csv')\n",
    "#read the 'FIT1043-Essay-Features-Submission.csv' file into dataframe and data is assigned to it \n",
    "data #Display data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.33200000e+03, 9.00000000e+02, 2.80000000e+01, ...,\n",
       "        2.17777778e-01, 7.50000000e+02, 7.50000000e+02],\n",
       "       [1.46500000e+03, 2.80000000e+02, 1.10000000e+01, ...,\n",
       "        1.82142857e-01, 3.39000000e+02, 3.16000000e+02],\n",
       "       [1.69600000e+03, 3.25000000e+02, 1.70000000e+01, ...,\n",
       "        2.83076923e-01, 3.52000000e+02, 3.37000000e+02],\n",
       "       ...,\n",
       "       [2.44800000e+03, 4.68000000e+02, 2.20000000e+01, ...,\n",
       "        2.15811966e-01, 5.40000000e+02, 5.26000000e+02],\n",
       "       [1.08100000e+03, 2.14000000e+02, 1.40000000e+01, ...,\n",
       "        2.94392523e-01, 2.59000000e+02, 2.56000000e+02],\n",
       "       [2.09400000e+03, 4.33000000e+02, 1.10000000e+01, ...,\n",
       "        2.79445727e-01, 5.01000000e+02, 4.78000000e+02]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_value = data.iloc[:,[1,2,3,6,10,12,14,15,16,17]].values \n",
    "# x_value is assigned to the features that I wanted which include chars,words,commas,avg_word_length,POS,prompt_words,\n",
    "#synonym_words,synonym_words / total_words, unstemmed and stemmed\n",
    "x_value\n",
    "# Display x_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.61007178,  2.80121047,  1.18878042, ..., -1.20921457,\n",
       "         1.76769065,  1.8945291 ],\n",
       "       [-0.7419504 , -0.84746338, -0.33538219, ..., -2.13238714,\n",
       "        -0.8210112 , -0.90046281],\n",
       "       [-0.47187118, -0.58264028,  0.20255756, ...,  0.48245131,\n",
       "        -0.73913012, -0.76522127],\n",
       "       ...,\n",
       "       [ 0.40734775,  0.25890869,  0.65084068, ..., -1.26014168,\n",
       "         0.44499628,  0.45195263],\n",
       "       [-1.19091326, -1.2358706 , -0.06641231, ...,  0.77559778,\n",
       "        -1.32489477, -1.28686723],\n",
       "       [-0.00653988,  0.05293517, -0.33538219, ...,  0.38838008,\n",
       "         0.19935304,  0.1428291 ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_value = sc.transform(x_value) #Normalize x_value\n",
    "x_value #Display x_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 3, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 3, 4, 4, 4, 4, 4, 3, 3, 3,\n",
       "       4, 4, 4, 4, 4, 4, 4, 3, 2, 4, 3, 3, 4, 3, 4, 4, 3, 3, 3, 4, 3, 3,\n",
       "       2, 3, 3, 4, 4, 3, 3, 4, 4, 4, 3, 4, 3, 4, 4, 4, 2, 3, 3, 4, 3, 4,\n",
       "       4, 4, 3, 4, 3, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 4, 3, 4, 2, 4, 4,\n",
       "       2, 3, 3, 3, 4, 3, 4, 4, 4, 4, 4, 3, 3, 4, 2, 3, 3, 4, 3, 3, 4, 4,\n",
       "       5, 3, 4, 4, 4, 3, 3, 4, 2, 3, 4, 4, 4, 3, 2, 4, 3, 4, 3, 2, 4, 4,\n",
       "       2, 3, 4, 3, 3, 4, 2, 3, 4, 4, 4, 3, 3, 4, 4, 3, 4, 4, 4, 3, 4, 3,\n",
       "       4, 3, 3, 3, 4, 4, 4, 3, 2, 3, 4, 4, 3, 3, 2, 4, 3, 4, 3, 3, 4, 4,\n",
       "       4, 3, 3, 4, 4, 3, 4, 4, 4, 4, 3, 3, 4, 3, 3, 4, 3, 4, 3, 4, 4, 3,\n",
       "       3], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = model.predict(x_value) \n",
    "# Predict the score by fitting x_value into the model and y_predicted is assigned to it.\n",
    "y_predicted #Display y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    4\n",
       "1    3\n",
       "2    3\n",
       "3    4\n",
       "4    4\n",
       "..  ..\n",
       "194  3\n",
       "195  4\n",
       "196  4\n",
       "197  3\n",
       "198  3\n",
       "\n",
       "[199 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(y_predicted) # Transform y_predicted into dataframe and res is assigned to it\n",
    "res #Display res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     score\n",
       "0        4\n",
       "1        3\n",
       "2        3\n",
       "3        4\n",
       "4        4\n",
       "..     ...\n",
       "194      3\n",
       "195      4\n",
       "196      4\n",
       "197      3\n",
       "198      3\n",
       "\n",
       "[199 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.columns = ['score']  # res now has the heading 'score'\n",
    "res #Display res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essayid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     essayid\n",
       "0       1623\n",
       "1       1143\n",
       "2        660\n",
       "3       1596\n",
       "4        846\n",
       "..       ...\n",
       "194     1226\n",
       "195      862\n",
       "196     1562\n",
       "197     1336\n",
       "198     1171\n",
       "\n",
       "[199 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essayid = data.iloc[:,[0]] # essayid is assigned to the first column of data which is 'essayid'\n",
    "essayid #Display essayid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = essayid.join(res) # Joining essayid and res on index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('32156944-Ng Kai Yi-1.csv', index = None) # Writing the result to csv file '32156944-Ng Kai Yi-1.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "After completing this assignment,I have more knowledge on how to build a model with better performance.I did some research on how to tune the hyperparameter of SVC so that the predicted data can have higher accuracy and better quadratic weighted kappa score.Moreover,I also gained knowledge on how to calculate quadratic weighted kappa score and what it indicates.Not to mention,I also learnt how confusion matrix work and how to analyze the confusion matrix by calculating accuracy,precision and recall.Furthermore,I also learnt how to differentiate binary classification and multi-class classification.I found that it is really interesting to compete among my friends on kaggle eventhough it is very challenging when I try to improve my QWK score hence it is a really good experience to me."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
